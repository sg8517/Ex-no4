{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvKAfjN9WLx_",
        "outputId": "974d47ee-41a3-453b-b9a1-9f1cb9b771da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GV_DeepLearning'...\n",
            "remote: Enumerating objects: 1607, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1607 (delta 4), reused 15 (delta 2), pack-reused 1589\u001b[K\n",
            "Receiving objects: 100% (1607/1607), 29.99 MiB | 37.83 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb2PYWhlWSks",
        "outputId": "f8d9484f-923f-416f-f1b6-6d488760b452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'dog-cat-full-dataset'...\n",
            "remote: Enumerating objects: 25027, done.\u001b[K\n",
            "remote: Total 25027 (delta 0), reused 0 (delta 0), pack-reused 25027\u001b[K\n",
            "Receiving objects: 100% (25027/25027), 541.62 MiB | 32.14 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "Checking out files: 100% (25001/25001), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/laxmimerit/dog-cat-full-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSvPnJHgWcXb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ibajRhyWe66",
        "outputId": "30de264d-a712-4377-9b0a-01845c59fc53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.2'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4zLKLQUWh6J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGhOdJKhWmai",
        "outputId": "16e9b51c-8e2f-41b7-9528-d5454e803bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/dog-cat-full-dataset/data/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-jQkpS8Wp9K",
        "outputId": "0fbb9783-86a8-4ad5-f899-534bc3d08e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/dog-cat-full-dataset/data/test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2kxmmFHWuRy"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrS0kKG_Wxg6"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', \n",
        "                               input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL7cMedKW1dy"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAy2XdyxW4pp"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A12K1XoqW706"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efKZ2PnOW_1B"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6dxGfEjXDjh"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awyvyGrhXIwK"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTlIGsLjXMlq",
        "outputId": "e41ec0f5-50d1-466d-baf0-d9c49af482e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.4790 - accuracy: 0.7699 - val_loss: 0.4350 - val_accuracy: 0.7948\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.4559 - accuracy: 0.7826 - val_loss: 0.4719 - val_accuracy: 0.7810\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 168s 269ms/step - loss: 0.4336 - accuracy: 0.7993 - val_loss: 0.4225 - val_accuracy: 0.8134\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 171s 273ms/step - loss: 0.4212 - accuracy: 0.8022 - val_loss: 0.4268 - val_accuracy: 0.8000\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.4054 - accuracy: 0.8164 - val_loss: 0.3929 - val_accuracy: 0.8218\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.3880 - accuracy: 0.8236 - val_loss: 0.4505 - val_accuracy: 0.7938\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.3801 - accuracy: 0.8275 - val_loss: 0.4231 - val_accuracy: 0.8174\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.3654 - accuracy: 0.8350 - val_loss: 0.4242 - val_accuracy: 0.8192\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.3598 - accuracy: 0.8392 - val_loss: 0.4272 - val_accuracy: 0.8210\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.3441 - accuracy: 0.8464 - val_loss: 0.4583 - val_accuracy: 0.8018\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 167s 268ms/step - loss: 0.3392 - accuracy: 0.8489 - val_loss: 0.3891 - val_accuracy: 0.8380\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.3254 - accuracy: 0.8594 - val_loss: 0.3891 - val_accuracy: 0.8432\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 167s 266ms/step - loss: 0.3132 - accuracy: 0.8623 - val_loss: 0.4074 - val_accuracy: 0.8310\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 165s 263ms/step - loss: 0.3021 - accuracy: 0.8683 - val_loss: 0.3816 - val_accuracy: 0.8492\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 165s 263ms/step - loss: 0.2956 - accuracy: 0.8739 - val_loss: 0.3659 - val_accuracy: 0.8478\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 165s 263ms/step - loss: 0.2826 - accuracy: 0.8790 - val_loss: 0.3757 - val_accuracy: 0.8494\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 0.2798 - accuracy: 0.8794 - val_loss: 0.4178 - val_accuracy: 0.8294\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 0.2730 - accuracy: 0.8844 - val_loss: 0.4111 - val_accuracy: 0.8314\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 165s 263ms/step - loss: 0.2621 - accuracy: 0.8860 - val_loss: 0.4487 - val_accuracy: 0.8238\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 167s 267ms/step - loss: 0.2525 - accuracy: 0.8900 - val_loss: 0.3868 - val_accuracy: 0.8450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66584d2a10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S9vXDVCAXQcQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/GV_DeepLearning/Dataset/SingleImage/cat_or_dog_1.jpg', \n",
        "                            target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFeCc5uRYX6p",
        "outputId": "4351886a-0de9-4cf7-c009-d03e2f920ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yycAf7pbY-1d",
        "outputId": "f499d8b3-7965-4146-fd46-67b793e59a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,217\n",
            "Trainable params: 813,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}